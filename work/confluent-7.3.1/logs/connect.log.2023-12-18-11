[2023-12-18 11:02:42,621] INFO [AdminClient clientId=adminclient-10] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:07:42,745] INFO [AdminClient clientId=adminclient-10] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:12:42,860] INFO [AdminClient clientId=adminclient-10] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:16:30,395] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2023-12-18 11:16:30,397] INFO [Producer clientId=producer-3] Resetting the last seen epoch of partition connect-configs-0 to 0 since the associated topicId changed from null to IbF5gmv6SZyD2XmabuXxFw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:16:30,402] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-sink-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2066)
[2023-12-18 11:16:30,402] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:229)
[2023-12-18 11:16:30,403] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:566)
[2023-12-18 11:16:30,406] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=6, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:627)
[2023-12-18 11:16:30,409] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=6, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:802)
[2023-12-18 11:16:30,409] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 6 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', leaderUrl='http://192.168.0.50:8083/', offset=5, connectorIds=[my-sink-connect, my-source-connect], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2256)
[2023-12-18 11:16:30,410] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 5 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1659)
[2023-12-18 11:16:30,411] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector my-sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1776)
[2023-12-18 11:16:30,411] INFO [my-sink-connect|worker] Creating connector my-sink-connect of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:300)
[2023-12-18 11:16:30,412] INFO [my-sink-connect|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-12-18 11:16:30,412] INFO [my-sink-connect|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-12-18 11:16:30,413] INFO [my-sink-connect|worker] Instantiated connector my-sink-connect with version 10.6.3 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:322)
[2023-12-18 11:16:30,413] INFO [my-sink-connect|worker] Finished creating connector my-sink-connect (org.apache.kafka.connect.runtime.Worker:347)
[2023-12-18 11:16:30,413] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1687)
[2023-12-18 11:16:30,415] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-0 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:16:30,415] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-4 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:16:30,416] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-1 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:16:30,416] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-2 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:16:30,416] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-3 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:16:30,419] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-12-18 11:16:30,420] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-12-18 11:16:30,421] INFO [my-sink-connect|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2023-12-18 11:16:30,431] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [my-sink-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2081)
[2023-12-18 11:16:30,432] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:229)
[2023-12-18 11:16:30,432] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:566)
[2023-12-18 11:16:30,435] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=7, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:627)
[2023-12-18 11:16:30,442] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=7, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:802)
[2023-12-18 11:16:30,442] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 7 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', leaderUrl='http://192.168.0.50:8083/', offset=7, connectorIds=[my-sink-connect, my-source-connect], taskIds=[my-sink-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2256)
[2023-12-18 11:16:30,442] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 7 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1659)
[2023-12-18 11:16:30,443] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task my-sink-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1701)
[2023-12-18 11:16:30,446] INFO [my-sink-connect|task-0] Creating task my-sink-connect-0 (org.apache.kafka.connect.runtime.Worker:619)
[2023-12-18 11:16:30,448] INFO [my-sink-connect|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2023-12-18 11:16:30,450] INFO [my-sink-connect|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-12-18 11:16:30,451] INFO [my-sink-connect|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2023-12-18 11:16:30,451] INFO [my-sink-connect|task-0] Instantiated task my-sink-connect-0 with version 10.6.3 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:634)
[2023-12-18 11:16:30,452] INFO [my-sink-connect|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-12-18 11:16:30,453] INFO [my-sink-connect|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task my-sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:647)
[2023-12-18 11:16:30,453] INFO [my-sink-connect|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-12-18 11:16:30,453] INFO [my-sink-connect|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task my-sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:653)
[2023-12-18 11:16:30,453] INFO [my-sink-connect|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task my-sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:660)
[2023-12-18 11:16:30,457] INFO [my-sink-connect|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1300)
[2023-12-18 11:16:30,458] INFO [my-sink-connect|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-12-18 11:16:30,458] INFO [my-sink-connect|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-12-18 11:16:30,460] INFO [my-sink-connect|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-my-sink-connect-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-my-sink-connect
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2023-12-18 11:16:30,469] WARN [my-sink-connect|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:385)
[2023-12-18 11:16:30,469] INFO [my-sink-connect|task-0] Kafka version: 7.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-18 11:16:30,469] INFO [my-sink-connect|task-0] Kafka commitId: 8628b0341c3c46766f141043367cc0052f75b090 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-18 11:16:30,469] INFO [my-sink-connect|task-0] Kafka startTimeMs: 1702865790469 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-18 11:16:30,478] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Subscribed to topic(s): my_topic_users (org.apache.kafka.clients.consumer.KafkaConsumer:973)
[2023-12-18 11:16:30,479] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1687)
[2023-12-18 11:16:30,480] INFO [my-sink-connect|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:49)
[2023-12-18 11:16:30,480] INFO [my-sink-connect|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3307/test
	connection.user = root
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:376)
[2023-12-18 11:16:30,483] INFO [my-sink-connect|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:68)
[2023-12-18 11:16:30,484] INFO [my-sink-connect|task-0] WorkerSinkTask{id=my-sink-connect-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:313)
[2023-12-18 11:16:30,484] INFO [my-sink-connect|task-0] WorkerSinkTask{id=my-sink-connect-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:198)
[2023-12-18 11:16:30,521] WARN [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Error while fetching metadata with correlation id 2 : {my_topic_users=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient:1105)
[2023-12-18 11:16:30,521] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Cluster ID: RAGZoIhVTsO7n4moHNR-bw (org.apache.kafka.clients.Metadata:287)
[2023-12-18 11:16:30,522] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Discovered group coordinator DESKTOP-2BQSN3N:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:897)
[2023-12-18 11:16:30,523] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-12-18 11:16:30,531] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Request joining group due to: need to re-join with the given member-id: connector-consumer-my-sink-connect-0-e3cba7f3-e56c-45cf-8ab5-584676c4380b (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1063)
[2023-12-18 11:16:30,532] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1063)
[2023-12-18 11:16:30,532] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-12-18 11:16:30,534] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Successfully joined group with generation Generation{generationId=1, memberId='connector-consumer-my-sink-connect-0-e3cba7f3-e56c-45cf-8ab5-584676c4380b', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:627)
[2023-12-18 11:16:30,636] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Resetting the last seen epoch of partition my_topic_users-0 to 0 since the associated topicId changed from null to bYLDup1yTrSP0KUVfTC0QQ (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:16:30,639] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Finished assignment for group at generation 1: {connector-consumer-my-sink-connect-0-e3cba7f3-e56c-45cf-8ab5-584676c4380b=Assignment(partitions=[my_topic_users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:705)
[2023-12-18 11:16:30,644] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Successfully synced group in generation Generation{generationId=1, memberId='connector-consumer-my-sink-connect-0-e3cba7f3-e56c-45cf-8ab5-584676c4380b', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:802)
[2023-12-18 11:16:30,644] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Notifying assignor about the new Assignment(partitions=[my_topic_users-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:300)
[2023-12-18 11:16:30,644] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Adding newly assigned partitions: my_topic_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:312)
[2023-12-18 11:16:30,648] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Found no committed offset for partition my_topic_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1538)
[2023-12-18 11:16:30,650] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Resetting offset for partition my_topic_users-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-2BQSN3N:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-12-18 11:16:46,581] INFO [Worker clientId=connect-1, groupId=connect-cluster] Resetting the last seen epoch of partition my_topic_users-0 to 0 since the associated topicId changed from null to bYLDup1yTrSP0KUVfTC0QQ (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:22:42,992] INFO [AdminClient clientId=adminclient-10] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:25:30,741] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:27:43,113] INFO [AdminClient clientId=adminclient-10] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:32:43,233] INFO [AdminClient clientId=adminclient-10] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:37:43,347] INFO [AdminClient clientId=adminclient-10] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:42:43,467] INFO [AdminClient clientId=adminclient-10] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:45:55,198] INFO [Producer clientId=producer-3] Resetting the last seen epoch of partition connect-configs-0 to 0 since the associated topicId changed from null to IbF5gmv6SZyD2XmabuXxFw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:45:55,204] INFO Successfully processed removal of connector 'my-sink-connect' (org.apache.kafka.connect.storage.KafkaConfigBackingStore:852)
[2023-12-18 11:45:55,204] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-sink-connect config removed (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2053)
[2023-12-18 11:45:55,205] INFO [Worker clientId=connect-1, groupId=connect-cluster] Handling connector-only config update by stopping connector my-sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:669)
[2023-12-18 11:45:55,205] INFO [my-sink-connect|worker] Stopping connector my-sink-connect (org.apache.kafka.connect.runtime.Worker:423)
[2023-12-18 11:45:55,205] INFO [my-sink-connect|worker] Scheduled shutdown for WorkerConnector{id=my-sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:257)
[2023-12-18 11:45:55,209] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-0 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:45:55,209] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-4 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:45:55,210] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-1 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:45:55,210] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-2 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:45:55,210] INFO [Producer clientId=producer-2] Resetting the last seen epoch of partition connect-status-3 to 0 since the associated topicId changed from null to _oIidf5WTcyncK2ZVA9Xjw (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:45:55,210] INFO [my-sink-connect|worker] Completed shutdown for WorkerConnector{id=my-sink-connect} (org.apache.kafka.connect.runtime.WorkerConnector:277)
[2023-12-18 11:45:55,211] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:229)
[2023-12-18 11:45:55,211] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:566)
[2023-12-18 11:45:55,214] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=8, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:627)
[2023-12-18 11:45:55,219] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=8, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:802)
[2023-12-18 11:45:55,221] INFO [my-sink-connect|worker] Stopping connector my-sink-connect (org.apache.kafka.connect.runtime.Worker:423)
[2023-12-18 11:45:55,221] INFO [my-sink-connect|task-0] Stopping task my-sink-connect-0 (org.apache.kafka.connect.runtime.Worker:1026)
[2023-12-18 11:45:55,221] WARN [my-sink-connect|worker] Ignoring stop request for unowned connector my-sink-connect (org.apache.kafka.connect.runtime.Worker:426)
[2023-12-18 11:45:55,221] WARN [my-sink-connect|worker] Ignoring await stop request for non-present connector my-sink-connect (org.apache.kafka.connect.runtime.Worker:451)
[2023-12-18 11:45:55,221] INFO [my-sink-connect|task-0] Stopping task (io.confluent.connect.jdbc.sink.JdbcSinkTask:165)
[2023-12-18 11:45:55,221] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Revoke previously assigned partitions my_topic_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:331)
[2023-12-18 11:45:55,222] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Member connector-consumer-my-sink-connect-0-e3cba7f3-e56c-45cf-8ab5-584676c4380b sending LeaveGroup request to coordinator DESKTOP-2BQSN3N:9092 (id: 2147483647 rack: null) due to the consumer is being closed (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1124)
[2023-12-18 11:45:55,222] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Resetting generation and member id due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1016)
[2023-12-18 11:45:55,222] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Request joining group due to: consumer pro-actively leaving the group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1063)
[2023-12-18 11:45:55,231] INFO [my-sink-connect|task-0] Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics:693)
[2023-12-18 11:45:55,233] INFO [my-sink-connect|task-0] Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics:697)
[2023-12-18 11:45:55,233] INFO [my-sink-connect|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-12-18 11:45:55,234] INFO [my-sink-connect|task-0] App info kafka.consumer for connector-consumer-my-sink-connect-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
[2023-12-18 11:45:55,237] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished stopping tasks in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2342)
[2023-12-18 11:45:55,238] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished flushing status backing store in preparation for rebalance (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2361)
[2023-12-18 11:45:55,238] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 8 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', leaderUrl='http://192.168.0.50:8083/', offset=9, connectorIds=[my-source-connect], taskIds=[], revokedConnectorIds=[my-sink-connect], revokedTaskIds=[my-sink-connect-0], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2256)
[2023-12-18 11:45:55,239] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1659)
[2023-12-18 11:45:55,239] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1687)
[2023-12-18 11:45:55,240] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:229)
[2023-12-18 11:45:55,240] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:566)
[2023-12-18 11:45:55,241] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=9, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:627)
[2023-12-18 11:45:55,244] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=9, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:802)
[2023-12-18 11:45:55,244] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 9 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', leaderUrl='http://192.168.0.50:8083/', offset=9, connectorIds=[my-source-connect], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2256)
[2023-12-18 11:45:55,244] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 9 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1659)
[2023-12-18 11:45:55,244] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1687)
[2023-12-18 11:46:05,856] INFO AbstractConfig values: 
 (org.apache.kafka.common.config.AbstractConfig:376)
[2023-12-18 11:46:05,861] INFO [Worker clientId=connect-1, groupId=connect-cluster] Connector my-sink-connect config updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2066)
[2023-12-18 11:46:05,861] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:229)
[2023-12-18 11:46:05,861] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:566)
[2023-12-18 11:46:05,864] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=10, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:627)
[2023-12-18 11:46:05,866] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=10, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:802)
[2023-12-18 11:46:05,866] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 10 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', leaderUrl='http://192.168.0.50:8083/', offset=10, connectorIds=[my-sink-connect, my-source-connect], taskIds=[], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2256)
[2023-12-18 11:46:05,866] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 10 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1659)
[2023-12-18 11:46:05,867] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connector my-sink-connect (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1776)
[2023-12-18 11:46:05,867] INFO [my-sink-connect|worker] Creating connector my-sink-connect of type io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:300)
[2023-12-18 11:46:05,868] INFO [my-sink-connect|worker] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-12-18 11:46:05,868] INFO [my-sink-connect|worker] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-12-18 11:46:05,869] INFO [my-sink-connect|worker] Instantiated connector my-sink-connect with version 10.6.3 of type class io.confluent.connect.jdbc.JdbcSinkConnector (org.apache.kafka.connect.runtime.Worker:322)
[2023-12-18 11:46:05,869] INFO [my-sink-connect|worker] Finished creating connector my-sink-connect (org.apache.kafka.connect.runtime.Worker:347)
[2023-12-18 11:46:05,869] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1687)
[2023-12-18 11:46:05,869] INFO SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-12-18 11:46:05,870] INFO EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-12-18 11:46:05,870] INFO [my-sink-connect|worker] Setting task configurations for 1 workers. (io.confluent.connect.jdbc.JdbcSinkConnector:51)
[2023-12-18 11:46:05,877] INFO [Worker clientId=connect-1, groupId=connect-cluster] Tasks [my-sink-connect-0] configs updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2081)
[2023-12-18 11:46:05,881] INFO [Worker clientId=connect-1, groupId=connect-cluster] Rebalance started (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:229)
[2023-12-18 11:46:05,881] INFO [Worker clientId=connect-1, groupId=connect-cluster] (Re-)joining group (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:566)
[2023-12-18 11:46:05,881] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully joined group with generation Generation{generationId=11, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:627)
[2023-12-18 11:46:05,884] INFO [Worker clientId=connect-1, groupId=connect-cluster] Successfully synced group in generation Generation{generationId=11, memberId='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', protocol='sessioned'} (org.apache.kafka.connect.runtime.distributed.WorkerCoordinator:802)
[2023-12-18 11:46:05,884] INFO [Worker clientId=connect-1, groupId=connect-cluster] Joined group at generation 11 with protocol version 2 and got assignment: Assignment{error=0, leader='connect-1-5fe3efe7-8e24-423d-b70b-71765d4edb5e', leaderUrl='http://192.168.0.50:8083/', offset=12, connectorIds=[my-sink-connect, my-source-connect], taskIds=[my-sink-connect-0], revokedConnectorIds=[], revokedTaskIds=[], delay=0} with rebalance delay: 0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2256)
[2023-12-18 11:46:05,884] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting connectors and tasks using config offset 12 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1659)
[2023-12-18 11:46:05,886] INFO [Worker clientId=connect-1, groupId=connect-cluster] Starting task my-sink-connect-0 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1701)
[2023-12-18 11:46:05,886] INFO [my-sink-connect|task-0] Creating task my-sink-connect-0 (org.apache.kafka.connect.runtime.Worker:619)
[2023-12-18 11:46:05,887] INFO [my-sink-connect|task-0] ConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig:376)
[2023-12-18 11:46:05,887] INFO [my-sink-connect|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-12-18 11:46:05,887] INFO [my-sink-connect|task-0] TaskConfig values: 
	task.class = class io.confluent.connect.jdbc.sink.JdbcSinkTask
 (org.apache.kafka.connect.runtime.TaskConfig:376)
[2023-12-18 11:46:05,887] INFO [my-sink-connect|task-0] Instantiated task my-sink-connect-0 with version 10.6.3 of type io.confluent.connect.jdbc.sink.JdbcSinkTask (org.apache.kafka.connect.runtime.Worker:634)
[2023-12-18 11:46:05,888] INFO [my-sink-connect|task-0] JsonConverterConfig values: 
	converter.type = key
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-12-18 11:46:05,888] INFO [my-sink-connect|task-0] Set up the key converter class org.apache.kafka.connect.json.JsonConverter for task my-sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:647)
[2023-12-18 11:46:05,888] INFO [my-sink-connect|task-0] JsonConverterConfig values: 
	converter.type = value
	decimal.format = BASE64
	schemas.cache.size = 1000
	schemas.enable = true
 (org.apache.kafka.connect.json.JsonConverterConfig:376)
[2023-12-18 11:46:05,888] INFO [my-sink-connect|task-0] Set up the value converter class org.apache.kafka.connect.json.JsonConverter for task my-sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:653)
[2023-12-18 11:46:05,889] INFO [my-sink-connect|task-0] Set up the header converter class org.apache.kafka.connect.storage.SimpleHeaderConverter for task my-sink-connect-0 using the worker config (org.apache.kafka.connect.runtime.Worker:660)
[2023-12-18 11:46:05,889] INFO [my-sink-connect|task-0] Initializing: org.apache.kafka.connect.runtime.TransformationChain{} (org.apache.kafka.connect.runtime.Worker:1300)
[2023-12-18 11:46:05,889] INFO [my-sink-connect|task-0] SinkConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.SinkConnectorConfig:376)
[2023-12-18 11:46:05,890] INFO [my-sink-connect|task-0] EnrichedConnectorConfig values: 
	config.action.reload = restart
	connector.class = io.confluent.connect.jdbc.JdbcSinkConnector
	errors.deadletterqueue.context.headers.enable = false
	errors.deadletterqueue.topic.name = 
	errors.deadletterqueue.topic.replication.factor = 3
	errors.log.enable = false
	errors.log.include.messages = false
	errors.retry.delay.max.ms = 60000
	errors.retry.timeout = 0
	errors.tolerance = none
	header.converter = null
	key.converter = null
	name = my-sink-connect
	predicates = []
	tasks.max = 1
	topics = [my_topic_users]
	topics.regex = 
	transforms = []
	value.converter = null
 (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:376)
[2023-12-18 11:46:05,890] INFO [my-sink-connect|task-0] ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = connector-consumer-my-sink-connect-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = connect-my-sink-connect
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
 (org.apache.kafka.clients.consumer.ConsumerConfig:376)
[2023-12-18 11:46:05,897] WARN [my-sink-connect|task-0] These configurations '[metrics.context.connect.kafka.cluster.id, metrics.context.connect.group.id]' were supplied but are not used yet. (org.apache.kafka.clients.consumer.ConsumerConfig:385)
[2023-12-18 11:46:05,897] INFO [my-sink-connect|task-0] Kafka version: 7.3.1-ccs (org.apache.kafka.common.utils.AppInfoParser:119)
[2023-12-18 11:46:05,898] INFO [my-sink-connect|task-0] Kafka commitId: 8628b0341c3c46766f141043367cc0052f75b090 (org.apache.kafka.common.utils.AppInfoParser:120)
[2023-12-18 11:46:05,898] INFO [my-sink-connect|task-0] Kafka startTimeMs: 1702867565897 (org.apache.kafka.common.utils.AppInfoParser:121)
[2023-12-18 11:46:05,899] INFO [Worker clientId=connect-1, groupId=connect-cluster] Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1687)
[2023-12-18 11:46:05,899] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Subscribed to topic(s): my_topic_users (org.apache.kafka.clients.consumer.KafkaConsumer:973)
[2023-12-18 11:46:05,899] INFO [my-sink-connect|task-0] Starting JDBC Sink task (io.confluent.connect.jdbc.sink.JdbcSinkTask:49)
[2023-12-18 11:46:05,899] INFO [my-sink-connect|task-0] JdbcSinkConfig values: 
	auto.create = true
	auto.evolve = true
	batch.size = 3000
	connection.attempts = 3
	connection.backoff.ms = 10000
	connection.password = [hidden]
	connection.url = jdbc:mysql://localhost:3307/test
	connection.user = root
	db.timezone = UTC
	delete.enabled = false
	dialect.name = 
	fields.whitelist = []
	insert.mode = insert
	max.retries = 10
	pk.fields = []
	pk.mode = none
	quote.sql.identifiers = ALWAYS
	retry.backoff.ms = 3000
	table.name.format = ${topic}
	table.types = [TABLE]
 (io.confluent.connect.jdbc.sink.JdbcSinkConfig:376)
[2023-12-18 11:46:05,900] INFO [my-sink-connect|task-0] Initializing writer using SQL dialect: MySqlDatabaseDialect (io.confluent.connect.jdbc.sink.JdbcSinkTask:68)
[2023-12-18 11:46:05,900] INFO [my-sink-connect|task-0] WorkerSinkTask{id=my-sink-connect-0} Sink task finished initialization and start (org.apache.kafka.connect.runtime.WorkerSinkTask:313)
[2023-12-18 11:46:05,900] INFO [my-sink-connect|task-0] WorkerSinkTask{id=my-sink-connect-0} Executing sink task (org.apache.kafka.connect.runtime.WorkerSinkTask:198)
[2023-12-18 11:46:05,903] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Resetting the last seen epoch of partition my_topic_users-0 to 0 since the associated topicId changed from null to bYLDup1yTrSP0KUVfTC0QQ (org.apache.kafka.clients.Metadata:402)
[2023-12-18 11:46:05,903] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Cluster ID: RAGZoIhVTsO7n4moHNR-bw (org.apache.kafka.clients.Metadata:287)
[2023-12-18 11:46:05,903] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Discovered group coordinator DESKTOP-2BQSN3N:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:897)
[2023-12-18 11:46:05,904] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-12-18 11:46:05,906] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Request joining group due to: need to re-join with the given member-id: connector-consumer-my-sink-connect-0-bcb7ebe9-b6d2-4f49-bf46-08b11cf5bbe6 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1063)
[2023-12-18 11:46:05,907] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Request joining group due to: rebalance failed due to 'The group member needs to have a valid member id before actually entering a consumer group.' (MemberIdRequiredException) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1063)
[2023-12-18 11:46:05,907] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] (Re-)joining group (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:566)
[2023-12-18 11:46:05,908] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Successfully joined group with generation Generation{generationId=3, memberId='connector-consumer-my-sink-connect-0-bcb7ebe9-b6d2-4f49-bf46-08b11cf5bbe6', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:627)
[2023-12-18 11:46:05,908] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Finished assignment for group at generation 3: {connector-consumer-my-sink-connect-0-bcb7ebe9-b6d2-4f49-bf46-08b11cf5bbe6=Assignment(partitions=[my_topic_users-0])} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:705)
[2023-12-18 11:46:05,915] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Successfully synced group in generation Generation{generationId=3, memberId='connector-consumer-my-sink-connect-0-bcb7ebe9-b6d2-4f49-bf46-08b11cf5bbe6', protocol='range'} (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:802)
[2023-12-18 11:46:05,915] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Notifying assignor about the new Assignment(partitions=[my_topic_users-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:300)
[2023-12-18 11:46:05,915] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Adding newly assigned partitions: my_topic_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:312)
[2023-12-18 11:46:05,916] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Found no committed offset for partition my_topic_users-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1538)
[2023-12-18 11:46:05,918] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Resetting offset for partition my_topic_users-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[DESKTOP-2BQSN3N:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
[2023-12-18 11:52:43,583] INFO [AdminClient clientId=adminclient-10] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient:937)
[2023-12-18 11:54:51,931] INFO [Worker clientId=connect-1, groupId=connect-cluster] Session key updated (org.apache.kafka.connect.runtime.distributed.DistributedHerder:2124)
[2023-12-18 11:55:06,301] INFO [my-sink-connect|task-0] [Consumer clientId=connector-consumer-my-sink-connect-0, groupId=connect-my-sink-connect] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:937)
